{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import pandas as pd\n",
    "sys.path.append(\"/pfs/work7/workspace/scratch/tu_zxobe27-master_thesis/code\")\n",
    "os.chdir(\"/pfs/work7/workspace/scratch/tu_zxobe27-master_thesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.download import download_agent\n",
    "from data.preprocess.misc import preprocess_boundaries\n",
    "from data.preprocess.river_network import preprocess_rivers, river_network\n",
    "\n",
    "fetch_instructions = pd.read_json(\"setup/fetch.json\")\n",
    "def get_fetch_instructions(id):\n",
    "    return fetch_instructions[fetch_instructions[\"id\"] == id].to_dict(orient = \"records\")[0]\n",
    "\n",
    "agent = download_agent(\"/pfs/work7/workspace/scratch/tu_zxobe27-master_thesis/\", \"BRA\", 2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Land Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.fetch(get_fetch_instructions(\"igbe_lulc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.fetch(get_fetch_instructions(\"lc_esacci_300\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.fetch(get_fetch_instructions(\"lc_glc_30\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc\n",
    "#### Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.fetch(get_fetch_instructions(\"msc_gadm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_boundaries(os.getcwd() + \"/\", \"BRA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.fetch(get_fetch_instructions(\"msc_rivers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_rivers(os.getcwd() + \"/\", \"BRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers = gpd.read_feather(\"/pfs/work7/workspace/scratch/tu_zxobe27-master_thesis/data/misc/msc_rivers.feather\").to_crs(5641)\n",
    "boundaries = gpd.read_file(\"/pfs/work7/workspace/scratch/tu_zxobe27-master_thesis/data/misc/raw/gadm/gadm41_BRA_2.json\", engine = \"pyogrio\").to_crs(5641)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivers_brazil = river_network(rivers[(rivers.NORIOCOMP != \"Linha de Costa\")],\n",
    "                              boundaries,\n",
    "                              rivers[(rivers.NORIOCOMP == \"Linha de Costa\")])\n",
    "# explode multi-geometries\n",
    "rivers_brazil.explode_rivers()\n",
    "rivers_brazil.update_vertices()\n",
    "# compute nodes\n",
    "rivers_brazil.update_network_nodes()\n",
    "rivers_brazil.update_border_nodes() # (multiprocessing-enabled: est. 4min)\n",
    "rivers_brazil.update_end_nodes()\n",
    "rivers_brazil.update_vertices()\n",
    "rivers_brazil.update_nodes()\n",
    "# break lines at nodes\n",
    "rivers_brazil.break_lines_at_nodes() # (multiprocessing-enabled: est. 10min)\n",
    "rivers_brazil.explode_rivers()\n",
    "rivers_brazil.update_vertices()\n",
    "# clean shapefile\n",
    "rivers_brazil.update_estuary_nodes()\n",
    "rivers_brazil.clean_shapefile()\n",
    "rivers_brazil.store_network(\"/pfs/work7/workspace/scratch/tu_zxobe27-master_thesis/data/river_netowork/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Create a new SQLite database\n",
    "conn = sqlite3.connect('/pfs/work7/workspace/scratch/tu_zxobe27-master_thesis/data/imagery/imagery.db')\n",
    "\n",
    "# Create tables\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('''\n",
    "    CREATE TABLE GridCells (\n",
    "        CellID INTEGER PRIMARY KEY,\n",
    "        Row INTEGER,\n",
    "        Column INTEGER,\n",
    "        X REAL,\n",
    "        Y REAL,\n",
    "        Internal BOOLEAN\n",
    "    )\n",
    "''')\n",
    "cursor.execute('''\n",
    "    CREATE TABLE SubGridCells (\n",
    "        SubCellID INTEGER PRIMARY KEY,\n",
    "        CellID INTEGER,\n",
    "        X REAL,\n",
    "        Y REAL,\n",
    "        ShareValid REAL\n",
    "    )\n",
    "''')\n",
    "cursor.execute('''\n",
    "    CREATE TABLE RemoteImageFiles (\n",
    "        RemoteImageFileID INTEGER PRIMARY KEY,\n",
    "        CellID INTEGER,\n",
    "        Year INTEGER,\n",
    "        RemoteFilePath TEXT,\n",
    "        RemoteFileSize INTEGER,\n",
    "        Processed BOOLEAN\n",
    "    )\n",
    "''')\n",
    "cursor.execute('''\n",
    "    CREATE TABLE LocalImageFiles (\n",
    "        LocalImageFileID INTEGER PRIMARY KEY,\n",
    "        RemoteImageFileID INTEGER,\n",
    "        CellID INTEGER,\n",
    "        SubCellID INTEGER,\n",
    "        Year INTEGER,\n",
    "        LocalFilePath TEXT,\n",
    "        LocalFileSize INTEGER\n",
    "    )\n",
    "''')\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Started export task ***\n",
      "--- Task status ---\n",
      "{'state': 'READY', 'description': 'mapbiomas_2010', 'creation_timestamp_ms': 1708782512740, 'update_timestamp_ms': 1708782512740, 'start_timestamp_ms': 0, 'task_type': 'EXPORT_IMAGE', 'id': 'OMXIGF4N5BZ6FZCSL5IHMNRO', 'name': 'projects/master-thesis-414809/operations/OMXIGF4N5BZ6FZCSL5IHMNRO'}\n",
      "--- Task status ---\n"
     ]
    }
   ],
   "source": [
    "agent.fetch(get_fetch_instructions(\"im_mapbiomas_30\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the land cover classes\n",
    "classes = pd.read_excel(\"data/land_cover/lulc_classes_conv.xlsx\")\n",
    "# forward fill the missing values\n",
    "classes[[\"Level \" + str(x) for x in range(1, 3)]] = classes[[\"Level \" + str(x) for x in range(1, 3)]].ffill()\n",
    "# create a new column with the classes separated in an array\n",
    "classes[\"igbe_class\"] = classes[\"IBGE (1999; 2012) Classification \"].str.split(\",\")\n",
    "# explode the array to create a new row for each class\n",
    "cov_table = classes[[\"Level \" + str(x) for x in range(1, 3)] + [\"igbe_class\"]].explode(\"igbe_class\").dropna()\n",
    "# strip the whitespace from the class names\n",
    "cov_table[\"igbe_class\"] = cov_table[\"igbe_class\"].str.strip()\n",
    "# rename the columns \n",
    "cov_table.columns = [\"level_1\", \"level_2\", \"igbe_class\"]\n",
    "# export the table\n",
    "cov_table.to_csv(\"data/land_cover/lulc_classes.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
